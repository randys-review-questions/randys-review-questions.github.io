Id,Question,Type,Preformatted,Image,Option 1,Image 1,Option 2,Image 2,Option 3,Image 3,Option 4,Image 4,Option 5,Image 5,Option 6,Image 6,Option 7,Image 7,Option 8,Image 8,Option 9,Image 9,Option 10,Image 10,Option 11,Image 11,Option 12,Image 12,Option 13,Image 13,Option 14,Image 14,Option 15,Image 15,Correct Answer
1,"Algorithms that query and analyze data in a database often have to make tradeoffs between privacy, usability, accuracy, and performance. Encrypting the execution of queries sacrifices which of the following characteristics in order to improve the other three?",MC,,,Privacy,,Usability,,Accuracy,,Performance,,,,,,,,,,,,,,,,,,,,,,,,4
2,Which of the following best describes differential privacy?,MC,,,Differential privacy describes algorithms that rely on a trusted data curator to process raw data and implement privacy-preserving techniques.,,Differential privacy is an algorithm that involves adding a certain amount of Laplace noise depending on a privacy budget to individual data points in order to preserve data privacy.,,"Differential privacy describes algorithms that make it so given two input datasets that differ by at most one row, one cannot use query outputs to distinguish between the datasets.",,Differential privacy is an algorithm that involves performing computations on encrypted data to protect the privacy of computations.,,,,,,,,,,,,,,,,,,,,,,,,3
3,Which of the following database querying systems is 100% private?,MC,,,A system that always returns the exact result of a query,,"A system that always returns a noisy result, i.e. the result plus or minus some small, random number",,A system that always returns a query result of 0,,There is no way to make a database querying system 100% private.,,,,,,,,,,,,,,,,,,,,,,,,3
4,Which of the following is true about central differential privacy but not true about local differential privacy?,MC,,,Raw data is provided to a trusted data curator.,,Raw data is provided to trusted analysts.,,Noisy data is provided to an untrusted data curator.,,Noisy data is provided to untrusted analysts.,,,,,,,,,,,,,,,,,,,,,,,,1
5,"Suppose that you conducted a survey that asked 100 citizens of Medford, MA whether they liked dogs or cats more. Further suppose that you used Randomized Response and your final results were: 35 people liked dogs more and 65 people liked cats more. Which of the following is the best estimate of what the true results would have been without Randomized Response?",MC,,,20 people like dogs more and 80 people like cats more.,,30 people like dogs more and 70 people like cats more.,,35 people like dogs more and 65 people like cats more.,,40 people like dogs more and 60 people like cats more.,,,,,,,,,,,,,,,,,,,,,,,,1
6,"In the context of differential privacy, an increased privacy budget typically...",MC,,,provides more privacy but less accuracy in results.,,provides less privacy but more accuracy in results.,,provides more privacy with no effect on the accuracy of the results.,,provides less accuracy with no effect on the accuracy of the results.,,,,,,,,,,,,,,,,,,,,,,,,2
7,"Which of the following expressions evaluates to the variance of the result of query \(q\) when using a system that is differentially private by adding Laplace noise to the true result?

<i>Let \(\epsilon\) refer to the privacy budget, and let \(\text{GS}(q)\) refer to the Global Sensitivity of query \(q\).</i>",MC,,,\(2(\frac{\epsilon}{\text{GS}(q)})^2\),,\(2(\frac{\text{GS}(q)}{\epsilon})^2\),,\((\frac{2\epsilon}{\text{GS}(q)})^2\),,\((\frac{2\text{GS}(q)}{\epsilon})^2\),,,,,,,,,,,,,,,,,,,,,,,,2
8,"When applied to differentially private systems, cryptography is most often designed to ensure privacy in...",MC,,,the data stored in the databases.,,the process of updating the data stored in the databases.,,the queries made to the databases.,,the process of computing the answers to queries made to the databases.,,,,,,,,,,,,,,,,,,,,,,,,4
9,Trusted Execution Environments help maintain the privacy of _____ while running in an untrusted cloud.,MC,,,data but not code,,code but not data,,both code and data,,neither code nor data,,,,,,,,,,,,,,,,,,,,,,,,3
10,Which Python library allows one to query data from a database in a differentially private manner?,MC,,,<code>dpsql</code>,,<code>snsql</code>,,<code>dppandas</code>,,<code>snpandas</code>,,,,,,,,,,,,,,,,,,,,,,,,2
11,"Consider an airport that measures how busy different terminals are by placing sensors on the escalators that make updates to the data in some encrypted central server whenever they detect someone going up or down the escalator, providing basic information about the person using the escalator and the terminal number but <strong>not</strong> the exact sensor where the update came from. Based on this system, is the location of the people within the airport terminal private?",MC,,,"Yes, because the exact location of the individuals that triggered the sensor is not known.",,"Yes, because the central server storing this information is encrypted.",,"No, because this system is vulnerable to query leakage.",,"No, because this system is vulnerable to update pattern leakage.",,,,,,,,,,,,,,,,,,,,,,,,4
12,"Suppose that Illumination Hospital released deidentified sensitive data regarding patient medical information, but Charlie (an adversary) managed to reidentify the patients that contributed to the data by solving a series of constraints to find the only possible way that the published deidentified data could have been achieved. Charlie just performed a(n)...",MC,,,data reconstruction attack.,,post-processing attack.,,distributed denial-of-service attack.,,timing attack.,,,,,,,,,,,,,,,,,,,,,,,,1
13,Which of the following differentially private systems was developed first?,MC,,,Airavat,,DJoin,,FLEX,,PINQ,,,,,,,,,,,,,,,,,,,,,,,,4
14,"In <i>Privacy Loss in Apple's Implementation of Differential Privacy on MacOS 10.12</i> by Jun Tang et al., the authors, via reverse engineering methods, concluded that Apple's differential privacy method possibly...",MC,,,bounded users' overall privacy loss to a level that is lower than or equal to what is considered acceptable by the community.,,bounded users' overall privacy loss to a level that is significantly higher than what is considered acceptable by the community.,,kept users' overall privacy loss unbounded.,,sold a significant amount of user data to the exact groups that Apple claimed they would not sell to.,,,,,,,,,,,,,,,,,,,,,,,,3
15,"<i>Differential Privacy Under Fire</i> by Andreas Haeberlen, Benjamin C. Pierce, and Arjun Narayan proposes one solution to differential privacy systems that are vulnerable to timing attacks. This solution requires that for some timing threshold \(T\), all queries that take less than \(T\) time to compute will have the return of their result delayed until \(T\) time has passed. What is the solution for queries that take longer than \(T\) time?",MC,,,"Return the result when the computation finishes, even if it takes longer than \(T\) time to do so.",,Return some preset default value at time \(T\).,,Throw a query runtime error at time \(T\).,,Dynamically adjust the value of \(T\) to accommodate the longest running query encountered so far.,,,,,,,,,,,,,,,,,,,,,,,,2
